
@inproceedings{liu_crawlabel_2022,
	address = {Pittsburgh Pennsylvania},
	title = {{CrawLabel}: computing natural-language labels for {UI} test cases},
	isbn = {978-1-4503-9286-0},
	shorttitle = {{CrawLabel}},
	url = {https://dl.acm.org/doi/10.1145/3524481.3527229},
	doi = {10.1145/3524481.3527229},
	abstract = {End-to-end test cases that exercise the application under test via its user interface (UI) are known to be hard for developers to read and understand; consequently, diagnosing failures in these tests and maintaining them can be tedious. Techniques for computing natural-language descriptions of test cases can help increase test readability. However, so far, such techniques have been developed for unit test cases; they are not applicable to end-to-end test cases. In this paper, we focus on the problem of computing naturallanguage labels for the steps of end-to-end UI test cases for web applications. We present two techniques that apply natural-language processing to information available in the browser document object model (DOM). The first technique is an instance of a supervised approach in which labeling-relevant DOM attributes are ranked via manual analysis and fed into label computation. However, supervised approach requires a training dataset. So we propose the second technique, which is unsupervised: it leverages probabilistic contextfree grammar learning to compute dominant DOM attributes automatically. We implemented these techniques, along with two simpler baseline techniques, in a tool called CrawLabel (available as a plugin to Crawljax, a state-of-the-art UI test-generation tool for web applications) and evaluated their effectiveness on open-source web applications. Our results indicate that the supervised approach can achieve precision, recall, and F1-score of 83.38, 60.64, and 66.40, respectively. The unsupervised approach, although less effective, is competitive, achieving scores of 72.37, 58.12, and 59.77. We highlight key results and discuss the implications of our findings.},
	language = {en},
	urldate = {2024-05-01},
	booktitle = {Proceedings of the 3rd {ACM}/{IEEE} {International} {Conference} on {Automation} of {Software} {Test}},
	publisher = {ACM},
	author = {Liu, Yu and Yandrapally, Rahulkrishna and Kalia, Anup K. and Sinha, Saurabh and Tzoref-Brill, Rachel and Mesbah, Ali},
	month = may,
	year = {2022},
	pages = {103--114},
	file = {Liu et al. - 2022 - CrawLabel computing natural-language labels for U.pdf:/home/timo/Zotero/storage/3JB674LM/Liu et al. - 2022 - CrawLabel computing natural-language labels for U.pdf:application/pdf},
}

@misc{yu_universally_2022,
	title = {Universally {Adaptive} {Cross}-{Platform} {Reinforcement} {Learning} {Testing} via {GUI} {Image} {Understanding}},
	url = {http://arxiv.org/abs/2208.09116},
	abstract = {With the rapid development of the Internet, more and more applications (app) are playing an important role in various aspects of the world. Among all apps, mobile apps and web apps are dominant in people’s daily life and all industries. In order to tackle the challenges in ensuring the app quality, many approaches have been adopted to improve app GUI testing, including random technologies, model-based technologies, etc. However, existing approaches are still insufﬁcient in reaching high code coverage, constructing high quality models, and achieving generalizability. Besides, current approaches is heavily dependent on the execution platforms (i.e., Android, Web). Apps of distinct platforms share commonalities in GUI design, which inspires us to propose a platform-independent approach with the development of computer vision algorithms.},
	language = {en},
	urldate = {2024-05-01},
	publisher = {arXiv},
	author = {Yu, Shengcheng and Fang, Chunrong and Liu, Yulei and Zhang, Ziqian and Yun, Yexiao and Li, Xin and Chen, Zhenyu},
	month = aug,
	year = {2022},
	note = {arXiv:2208.09116 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {Yu et al. - 2022 - Universally Adaptive Cross-Platform Reinforcement .pdf:/home/timo/Zotero/storage/CYA9BSIK/Yu et al. - 2022 - Universally Adaptive Cross-Platform Reinforcement .pdf:application/pdf},
}

@inproceedings{chang_reinforcement_2023,
	address = {Melbourne, Australia},
	title = {A {Reinforcement} {Learning} {Approach} to {Generating} {Test} {Cases} for {Web} {Applications}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350324020},
	url = {https://ieeexplore.ieee.org/document/10173983/},
	doi = {10.1109/AST58925.2023.00006},
	abstract = {Web applications play an important role in modern society. Quality assurance of web applications requires lots of manual efforts. In this paper, we propose WebQT, an automatic test case generator for web applications based on reinforcement learning. Speciﬁcally, to increase testing efﬁciency, we design a new reward model, which encourages the agent to mimic human testers to interact with the web applications. To alleviate the problem of state redundancy, we further propose a novel state abstraction technique, which can identify different web pages with the same functionality as the same state, and yields a simpliﬁed state space. We evaluate WebQT on seven open-source web applications. The experimental results show that WebQT achieves 45.4\% more code coverage along with higher efﬁciency than the state-of-the-art technique. In addition, WebQT also reveals 69 exceptions in 11 real-world web applications.},
	language = {en},
	urldate = {2024-05-01},
	booktitle = {2023 {IEEE}/{ACM} {International} {Conference} on {Automation} of {Software} {Test} ({AST})},
	publisher = {IEEE},
	author = {Chang, Xiaoning and Liang, Zheheng and Zhang, Yifei and Cui, Lei and Long, Zhenyue and Wu, Guoquan and Gao, Yu and Chen, Wei and Wei, Jun and Huang, Tao},
	month = may,
	year = {2023},
	pages = {13--23},
	file = {Chang et al. - 2023 - A Reinforcement Learning Approach to Generating Te.pdf:/home/timo/Zotero/storage/TE2QA8TB/Chang et al. - 2023 - A Reinforcement Learning Approach to Generating Te.pdf:application/pdf;Chang et al. - 2023 - A Reinforcement Learning Approach to Generating Te.pdf:/home/timo/Zotero/storage/J6HABVGR/Chang et al. - 2023 - A Reinforcement Learning Approach to Generating Te.pdf:application/pdf},
}

@misc{zheng_automatic_2021,
	title = {Automatic {Web} {Testing} using {Curiosity}-{Driven} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2103.06018},
	abstract = {Web testing has long been recognized as a notoriously difﬁcult task. Even nowadays, web testing still heavily relies on manual efforts while automated web testing is far from achieving human-level performance. Key challenges in web testing include dynamic content update and deep bugs hiding under complicated user interactions and speciﬁc input values, which can only be triggered by certain action sequences in the huge search space. In this paper, we propose WebExplor, an automatic end-to-end web testing framework, to achieve an adaptive exploration of web applications. WebExplor adopts curiosity-driven reinforcement learning to generate high-quality action sequences (test cases) satisfying temporal logical relations. Besides, WebExplor incrementally builds an automaton during the online testing process, which provides high-level guidance to further improve the testing efﬁciency. We have conducted comprehensive evaluations of WebExplor on six real-world projects, a commercial SaaS web application, and performed an in-thewild study of the top 50 web applications in the world. The results demonstrate that in most cases WebExplor can achieve signiﬁcantly higher failure detection rate, code coverage and efﬁciency than existing state-of-the-art web testing techniques. WebExplor also detected 12 previously unknown failures in the commercial web application, which have been conﬁrmed and ﬁxed by the developers. Furthermore, our in-the-wild study further uncovered 3,466 exceptions and errors.},
	language = {en},
	urldate = {2024-05-01},
	publisher = {arXiv},
	author = {Zheng, Yan and Liu, Yi and Xie, Xiaofei and Liu, Yepang and Ma, Lei and Hao, Jianye and Liu, Yang},
	month = mar,
	year = {2021},
	note = {arXiv:2103.06018 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {Zheng et al. - 2021 - Automatic Web Testing using Curiosity-Driven Reinf.pdf:/home/timo/Zotero/storage/W55S7856/Zheng et al. - 2021 - Automatic Web Testing using Curiosity-Driven Reinf.pdf:application/pdf},
}

@misc{kollmer_empirical_nodate,
	title = {An {Empirical} {Assessment} of {Neural} {Embeddings} {Techniques} for {Web} {Testing}},
	abstract = {Automated web crawlers play a crucial role in End-to-End testing of web
applications for generating state-based models, where states represent distinct function-
alities and features of the application. However, a challenge in existing web crawling tech-
niques is the inclusion of near-duplicate states, marginally different pages representing
the same functionality. Near-duplicates adversely impact model-based testing tasks like
test case generation. This study introduces a novel approach for near-duplicate detection
in web application model inference, using a fine-tuned transformer-based deep learning
model, specifically distilBERT, to enhance the accuracy of near-duplicate detection.
The research evaluates DistilBERT in two configurations: its raw embeddings and a fine-
tuned version. We initially employ the raw distilBERT model to generate embeddings of
web pages which are used to classify state-pairs as distinct or (near-)duplicated. Subse-
quently, we refine the model through fine-tuning on the task of near-duplicate detection.
Our analysis compares both methods in terms of classification performance (F1 -Score)
and inference time on a dataset of web page state-pairs.
The results show that the fine-tuned DistilBERT surpasses the raw embeddings in clas-
sification accuracy, achieving a F1 -Score of 0.97 compared to 0.73. Furthermore, the ap-
proach results in a +10\% to +17\% improvement in F1 -Score w.r.t. previous near-duplicate
detection techniques. However, it is observed that the fine-tuned model, despite its su-
perior accuracy, operates slower than existing state-of-the-art near-duplicate detection
algorithms. Despite this, the fine-tuned DistilBERT’s improved accuracy and efficiency
indicate its potential for enhancing test generation in web applications, suggesting a move
towards more robust and efficient model-based testing strategies.},
	author = {Kollmer, Luca},
	file = {_.pdf:/home/timo/Zotero/storage/P8M75277/_.pdf:application/pdf},
}

@article{mesbah_crawling_2012,
	title = {Crawling {Ajax}-{Based} {Web} {Applications} through {Dynamic} {Analysis} of {User} {Interface} {State} {Changes}},
	volume = {6},
	issn = {1559-1131, 1559-114X},
	url = {https://dl.acm.org/doi/10.1145/2109205.2109208},
	doi = {10.1145/2109205.2109208},
	abstract = {Using
              JavaScript
              and dynamic DOM manipulation on the client side of Web applications is becoming a widespread approach for achieving rich interactivity and responsiveness in modern Web applications. At the same time, such techniques---collectively known as
              Ajax
              ---shatter the concept of webpages with unique URLs, on which traditional Web crawlers are based. This article describes a novel technique for crawling
              Ajax
              -based applications through automatic dynamic analysis of user-interface-state changes in Web browsers. Our algorithm scans the DOM tree, spots candidate elements that are capable of changing the state, fires events on those candidate elements, and incrementally infers a state machine that models the various navigational paths and states within an
              Ajax
              application. This inferred model can be used in program comprehension and in analysis and testing of dynamic Web states, for instance, or for generating a static version of the application. In this article, we discuss our sequential and concurrent
              Ajax
              crawling algorithms. We present our open source tool called
              Crawljax
              , which implements the concepts and algorithms discussed in this article. Additionally, we report a number of empirical studies in which we apply our approach to a number of open-source and industrial Web applications and elaborate on the obtained results.},
	language = {en},
	number = {1},
	urldate = {2024-04-18},
	journal = {ACM Transactions on the Web},
	author = {Mesbah, Ali and Van Deursen, Arie and Lenselink, Stefan},
	month = mar,
	year = {2012},
	pages = {1--30},
	file = {Mesbah et al. - 2012 - Crawling Ajax-Based Web Applications through Dynam.pdf:/home/timo/Zotero/storage/47LI95K2/Mesbah et al. - 2012 - Crawling Ajax-Based Web Applications through Dynam.pdf:application/pdf},
}

@article{yandrapally_fragment-based_2023,
	title = {Fragment-{Based} {Test} {Generation} {For} {Web} {Apps}},
	volume = {49},
	issn = {0098-5589, 1939-3520, 2326-3881},
	url = {http://arxiv.org/abs/2110.14043},
	doi = {10.1109/TSE.2022.3171295},
	abstract = {Automated model-based test generation presents a viable alternative to the costly manual test creation currently employed for regression testing of web apps. However, existing model inference techniques rely on threshold-based whole-page comparison to establish state equivalence, which cannot reliably identify near-duplicate web pages in modern web apps. Consequently, existing techniques produce inadequate models for dynamic web apps, and fragile test oracles, rendering the generated regression test suites ineffective. We propose a model-based test generation technique, FRAGGEN, that eliminates the need for thresholds, by employing a novel state abstraction based on page fragmentation to establish state equivalence. FRAGGEN also uses ﬁne-grained page fragment analysis to diversify state exploration and generate reliable test oracles. Our evaluation shows that FRAGGEN outperforms existing whole-page techniques by detecting more nearduplicates, inferring better web app models and generating test suites that are better suited for regression testing. On a dataset of 86,165 state-pairs, FRAGGEN detected 123\% more near-duplicates on average compared to whole-page techniques. The crawl models inferred by FRAGGEN have 62\% more precision and 70\% more recall on average. FRAGGEN also generates reliable regression test suites with test actions that have nearly 100\% success rate on the same version of the web app even if the execution environment is varied. The test oracles generated by FRAGGEN can detect 98.7\% of the visible changes in web pages while being highly robust, making them suitable for regression testing.},
	language = {en},
	number = {3},
	urldate = {2024-04-18},
	journal = {IEEE Transactions on Software Engineering},
	author = {Yandrapally, Rahulkrishna and Mesbah, Ali},
	month = mar,
	year = {2023},
	note = {arXiv:2110.14043 [cs]},
	keywords = {Computer Science - Software Engineering, D.2.5},
	pages = {1086--1101},
	file = {Yandrapally and Mesbah - 2023 - Fragment-Based Test Generation For Web Apps.pdf:/home/timo/Zotero/storage/YUMPD26R/Yandrapally and Mesbah - 2023 - Fragment-Based Test Generation For Web Apps.pdf:application/pdf},
}

@misc{stocco_neural_2023,
	title = {Neural {Embeddings} for {Web} {Testing}},
	url = {http://arxiv.org/abs/2306.07400},
	abstract = {Web test automation techniques employ web crawlers to automatically produce a web app model that is used for test generation. Existing crawlers rely on app-specific, threshold-based, algorithms to assess state equivalence. Such algorithms are hard to tune in the general case and cannot accurately identify and remove near-duplicate web pages from crawl models. Failing to retrieve an accurate web app model results in automated test generation solutions that produce redundant test cases and inadequate test suites that do not cover the web app functionalities adequately. In this paper, we propose WEBEMBED, a novel abstraction function based on neural network embeddings and threshold-free classifiers that can be used to produce accurate web app models during model-based test generation. Our evaluation on nine web apps shows that WEBEMBED outperforms state-of-the-art techniques by detecting near-duplicates more accurately, inferring better web app models that exhibit 22\% more precision, and 24\% more recall on average. Consequently, the test suites generated from these models achieve higher code coverage, with improvements ranging from 2\% to 59\% on an app-wise basis and averaging at 23\%.},
	language = {en},
	urldate = {2024-04-18},
	publisher = {arXiv},
	author = {Stocco, Andrea and Willi, Alexandra and Starace, Luigi Libero Lucio and Biagiola, Matteo and Tonella, Paolo},
	month = jun,
	year = {2023},
	note = {arXiv:2306.07400 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {Stocco et al. - 2023 - Neural Embeddings for Web Testing.pdf:/home/timo/Zotero/storage/94ZSKJ63/Stocco et al. - 2023 - Neural Embeddings for Web Testing.pdf:application/pdf},
}

@inproceedings{yandrapally_near-duplicate_2020,
	address = {Seoul South Korea},
	title = {Near-duplicate detection in web app model inference},
	isbn = {978-1-4503-7121-6},
	url = {https://dl.acm.org/doi/10.1145/3377811.3380416},
	doi = {10.1145/3377811.3380416},
	abstract = {Automated web testing techniques infer models from a given web app, which are used for test generation. From a testing viewpoint, such an inferred model should contain the minimal set of states that are distinct, yet, adequately cover the app’s main functionalities. In practice, models inferred automatically are aﬀected by near-duplicates, i.e., replicas of the same functional webpage differing only by small insigniﬁcant changes. We present the ﬁrst study of near-duplicate detection algorithms used in within app model inference. We ﬁrst characterize functional near-duplicates by classifying a random sample of state-pairs, from 493k pairs of webpages obtained from over 6,000 websites, into three categories, namely clone, near-duplicate, and distinct. We systematically compute thresholds that deﬁne the boundaries of these categories for each detection technique. We then use these thresholds to evaluate 10 near-duplicate detection techniques from three diﬀerent domains, namely, information retrieval, web testing, and computer vision on nine open-source web apps. Our study highlights the challenges posed in automatically inferring a model for any given web app. Our ﬁndings show that even with the best thresholds, no algorithm is able to accurately detect all functional near-duplicates within apps, without sacriﬁcing coverage.},
	language = {en},
	urldate = {2024-04-18},
	booktitle = {Proceedings of the {ACM}/{IEEE} 42nd {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Yandrapally, Rahulkrishna and Stocco, Andrea and Mesbah, Ali},
	month = jun,
	year = {2020},
	pages = {186--197},
	file = {Yandrapally et al. - 2020 - Near-duplicate detection in web app model inferenc.pdf:/home/timo/Zotero/storage/EIBTU367/Yandrapally et al. - 2020 - Near-duplicate detection in web app model inferenc.pdf:application/pdf},
}

@article{hicks_chatgpt_2024,
	title = {{ChatGPT} is bullshit},
	volume = {26},
	issn = {1572-8439},
	url = {https://doi.org/10.1007/s10676-024-09775-5},
	doi = {10.1007/s10676-024-09775-5},
	abstract = {Recently, there has been considerable interest in large language models: machine learning systems which produce human-like text and dialogue. Applications of these systems have been plagued by persistent inaccuracies in their output; these are often called “AI hallucinations”. We argue that these falsehoods, and the overall activity of large language models, is better understood as bullshit in the sense explored by Frankfurt (On Bullshit, Princeton, 2005): the models are in an important way indifferent to the truth of their outputs. We distinguish two ways in which the models can be said to be bullshitters, and argue that they clearly meet at least one of these definitions. We further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.},
	language = {en},
	number = {2},
	urldate = {2024-06-17},
	journal = {Ethics and Information Technology},
	author = {Hicks, Michael Townsen and Humphries, James and Slater, Joe},
	month = jun,
	year = {2024},
	keywords = {Artificial intelligence, Assertion, Bullshit, ChatGPT, Content, Frankfurt, Large language models, LLMs},
	pages = {38},
	file = {Full Text PDF:/home/timo/Zotero/storage/3UMEEE33/Hicks et al. - 2024 - ChatGPT is bullshit.pdf:application/pdf},
}

@article{sherin_qexplore_2023,
	title = {{QExplore}: {An} exploration strategy for dynamic web applications using guided search},
	volume = {195},
	issn = {0164-1212},
	shorttitle = {{QExplore}},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121222001881},
	doi = {10.1016/j.jss.2022.111512},
	abstract = {Dynamic exploration approaches play an important role in automating web testing and analysis. They are extensively used to explore the state-space of a web application for achieving complete coverage of the application’s functionality. Dynamic exploration approaches support end-to-end automation of testing to verify the correct behavior of a web application. However, existing approaches failed to explore the states behind the web forms and can get stuck in dynamic regions of web applications resulting in poor functionality coverage and diversity. Consequently, existing approaches are regressive in nature and sensitive to small DOM mutations which may not be interesting from a testing perspective. In this paper, we propose a dynamic exploration approach using guided search inspired by Q-learning that systematically explores dynamic web applications requiring less or no prior knowledge about the application. Our approach is implemented in a tool called QExplore and is empirically evaluated with six popular open-source and one real industrial application. The results show that QExplore achieved higher coverage with more diverse DOM than the existing state-of-the-art tools Crawljax and WebExplor. QExplore also results in a greater number of navigational paths, error states and distinct DOM states when compared with the existing tools.},
	urldate = {2024-07-03},
	journal = {Journal of Systems and Software},
	author = {Sherin, Salman and Muqeet, Asmar and Khan, Muhammad Uzair and Iqbal, Muhammad Zohaib},
	month = jan,
	year = {2023},
	keywords = {Automated testing, Coverage, Dynamic exploration, Guided search, Model generation, Q-learning, Reinforcement learning, Web application testing},
	pages = {111512},
	file = {ScienceDirect Snapshot:/home/timo/Zotero/storage/FNB9EBGF/S0164121222001881.html:text/html;Sherin et al. - 2023 - QExplore An exploration strategy for dynamic web .pdf:/home/timo/Zotero/storage/VMEVR2G7/Sherin et al. - 2023 - QExplore An exploration strategy for dynamic web .pdf:application/pdf},
}

@inproceedings{corazza_web_2021,
	title = {Web {Application} {Testing}: {Using} {Tree} {Kernels} to {Detect} {Near}-duplicate {States} in {Automated} {Model} {Inference}},
	shorttitle = {Web {Application} {Testing}},
	url = {http://arxiv.org/abs/2108.13322},
	doi = {10.1145/3475716.3484187},
	abstract = {In the context of End-to-End testing of web applications, automated exploration techniques (a.k.a. crawling) are widely used to infer state-based models of the site under test. These models, in which states represent features of the web application and transitions represent reachability relationships, can be used for several model-based testing tasks, such as test case generation. However, current exploration techniques often lead to models containing many near-duplicate states, i.e., states representing slightly different pages that are in fact instances of the same feature. This has a negative impact on the subsequent model-based testing tasks, adversely affecting, for example, size, running time, and achieved coverage of generated test suites. As a web page can be naturally represented by its tree-structured DOM representation, we propose a novel near-duplicate detection technique to improve the model inference of web applications, based on Tree Kernel (TK) functions. TKs are a class of functions that compute similarity between tree-structured objects, largely investigated and successfully applied in the Natural Language Processing domain. To evaluate the capability of the proposed approach in detecting near-duplicate web pages, we conducted preliminary classification experiments on a freely-available massive dataset of about 100k manually annotated web page pairs. We compared the classification performance of the proposed approach with other state-of-the-art near-duplicate detection techniques. Preliminary results show that our approach performs better than state-of-the-art techniques in the near-duplicate detection classification task. These promising results show that TKs can be applied to near-duplicate detection in the context of web application model inference, and motivate further research in this direction.},
	language = {en},
	urldate = {2024-07-03},
	booktitle = {Proceedings of the 15th {ACM} / {IEEE} {International} {Symposium} on {Empirical} {Software} {Engineering} and {Measurement} ({ESEM})},
	author = {Corazza, Anna and Di Martino, Sergio and Peron, Adriano and Starace, Luigi Libero Lucio},
	month = oct,
	year = {2021},
	note = {arXiv:2108.13322 [cs]},
	keywords = {Computer Science - Software Engineering, D.2.5},
	pages = {1--6},
	file = {arXiv.org Snapshot:/home/timo/Zotero/storage/VIP73MG5/2108.html:text/html;Corazza et al. - 2021 - Web Application Testing Using Tree Kernels to Det.pdf:/home/timo/Zotero/storage/HMBK8SIT/Corazza et al. - 2021 - Web Application Testing Using Tree Kernels to Det.pdf:application/pdf},
}

@inproceedings{biagiola_diversity-based_2019,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2019},
	title = {Diversity-based web test generation},
	isbn = {978-1-4503-5572-8},
	url = {https://doi.org/10.1145/3338906.3338970},
	doi = {10.1145/3338906.3338970},
	abstract = {Existing web test generators derive test paths from a navigational model of the web application, completed with either manually or randomly generated input values. However, manual test data selection is costly, while random generation often results in infeasible input sequences, which are rejected by the application under test. Random and search-based generation can achieve the desired level of model coverage only after a large number of test execution at- tempts, each slowed down by the need to interact with the browser during test execution. In this work, we present a novel web test generation algorithm that pre-selects the most promising candidate test cases based on their diversity from previously generated tests. As such, only the test cases that explore diverse behaviours of the application are considered for in-browser execution. We have implemented our approach in a tool called DIG. Our empirical evaluation on six real-world web applications shows that DIG achieves higher coverage and fault detection rates significantly earlier than crawling-based and search-based web test generators.},
	urldate = {2024-07-03},
	booktitle = {Proceedings of the 2019 27th {ACM} {Joint} {Meeting} on {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Biagiola, Matteo and Stocco, Andrea and Ricca, Filippo and Tonella, Paolo},
	month = aug,
	year = {2019},
	pages = {142--153},
	file = {Biagiola et al. - 2019 - Diversity-based web test generation.pdf:/home/timo/Zotero/storage/6A77HTDL/Biagiola et al. - 2019 - Diversity-based web test generation.pdf:application/pdf},
}

@inproceedings{biagiola_dependency-aware_2020,
	address = {Porto, Portugal},
	title = {Dependency-{Aware} {Web} {Test} {Generation}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72815-778-8},
	url = {https://ieeexplore.ieee.org/document/9159067/},
	doi = {10.1109/ICST46399.2020.00027},
	abstract = {Web crawlers can perform long running in-depth explorations of a web application, achieving high coverage of the navigational structure. However, a crawling trace cannot be easily turned into a minimal test suite that achieves the same coverage. In fact, when the crawling trace is segmented into test cases, two problems arise: (1) test cases are dependent on each other, therefore they may raise errors when executed in isolation, and (2) test cases are redundant, since the same targets are covered multiple times by different test cases. In this paper, we propose DANTE, a novel web test generator that computes the test dependencies associated with the test cases obtained from a crawling session, and uses them to eliminate redundant tests and produce executable test schedules. DANTE can effectively turn a web crawler into a test case generator that produces minimal test suites, composed only of feasible tests that contribute to achieve the ﬁnal coverage. Experimental results show that DANTE, on average, (1) reduces the error rate of the test cases obtained by crawling traces from 85\% to zero, (2) produces minimized test suites that are 84\% smaller than the initial ones, and (3) outperforms two competing crawling-based and modelbased techniques in terms of coverage and breakage rate.},
	language = {en},
	urldate = {2024-07-03},
	booktitle = {2020 {IEEE} 13th {International} {Conference} on {Software} {Testing}, {Validation} and {Verification} ({ICST})},
	publisher = {IEEE},
	author = {Biagiola, Matteo and Stocco, Andrea and Ricca, Filippo and Tonella, Paolo},
	month = oct,
	year = {2020},
	pages = {175--185},
	file = {Biagiola et al. - 2020 - Dependency-Aware Web Test Generation.pdf:/home/timo/Zotero/storage/C5V2IX7D/Biagiola et al. - 2020 - Dependency-Aware Web Test Generation.pdf:application/pdf},
}

@inproceedings{yu_incremental_2015,
	address = {Washington DC, DC, USA},
	title = {Incremental {Web} {Application} {Testing} {Using} {Page} {Object}},
	isbn = {978-1-4673-9688-2},
	url = {http://ieeexplore.ieee.org/document/7372274/},
	doi = {10.1109/HotWeb.2015.14},
	abstract = {Software testing is indispensable to assure software quality. Traditional software testing techniques are insufﬁcient for modern web applications due to their unique characteristics, such as highly dynamic generation of web pages and interactions with DOM elements. Meanwhile, existing web testing techniques are cumbersome to use in long-term maintenance and evolution because the tests are often brittle in the presence of fast changes to web pages.},
	language = {en},
	urldate = {2024-07-03},
	booktitle = {2015 {Third} {IEEE} {Workshop} on {Hot} {Topics} in {Web} {Systems} and {Technologies} ({HotWeb})},
	publisher = {IEEE},
	author = {Yu, Bing and Ma, Lei and Zhang, Cheng},
	month = nov,
	year = {2015},
	pages = {1--6},
	file = {Yu et al. - 2015 - Incremental Web Application Testing Using Page Obj.pdf:/home/timo/Zotero/storage/RPK8HZSN/Yu et al. - 2015 - Incremental Web Application Testing Using Page Obj.pdf:application/pdf},
}

@misc{yu_effective_2024,
	title = {Effective, {Platform}-{Independent} {GUI} {Testing} via {Image} {Embedding} and {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2208.09116},
	abstract = {Software applications have been playing an increasingly important role in various aspects of society. In particular, mobile apps and web apps are the most prevalent among all applications and are widely used in various industries as well as in people's daily lives. To help ensure mobile and web app quality, many approaches have been introduced to improve app GUI testing via automated exploration. Despite the extensive effort, existing approaches are still limited in reaching high code coverage, constructing high-quality models, and being generally applicable. Reinforcement learning-based approaches are faced with difficult challenges, including effective app state abstraction, reward function design, etc. Moreover, they heavily depend on the specific execution platforms, thus leading to poor generalizability and being unable to adapt to different platforms. We propose PIRLTest, an effective platform-independent approach for app testing. It utilizes computer vision and reinforcement learning techniques in a novel, synergistic manner for automated testing. It extracts the GUI widgets from GUI pages and characterizes the corresponding GUI layouts, embedding the GUI pages as states. The app GUI state combines the macroscopic perspective and the microscopic perspective, and attaches the critical semantic information from GUI images. This enables PIRLTest to be platform-independent and makes the testing approach generally applicable on different platforms. PIRLTest explores apps with the guidance of a curiosity-driven strategy, which uses a Q-network to estimate the values of specific state-action pairs to encourage more exploration in uncovered pages without platform dependency. The exploration will be assigned with rewards for all actions, which are designed considering both the app GUI states and the concrete widgets, to help the framework explore more uncovered pages.},
	language = {en},
	urldate = {2024-07-03},
	publisher = {arXiv},
	author = {Yu, Shengcheng and Fang, Chunrong and Li, Xin and Ling, Yuchen and Chen, Zhenyu and Su, Zhendong},
	month = jun,
	year = {2024},
	note = {arXiv:2208.09116 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {Yu et al. - 2024 - Effective, Platform-Independent GUI Testing via Im.pdf:/home/timo/Zotero/storage/CQVFZ3J9/Yu et al. - 2024 - Effective, Platform-Independent GUI Testing via Im.pdf:application/pdf},
}

@inproceedings{charikar_similarity_2002,
	address = {New York, NY, USA},
	series = {{STOC} '02},
	title = {Similarity estimation techniques from rounding algorithms},
	isbn = {978-1-58113-495-7},
	url = {https://doi.org/10.1145/509907.509965},
	doi = {10.1145/509907.509965},
	abstract = {(MATH) A locality sensitive hashing scheme is a distribution on a family \${\textbackslash}F\$ of hash functions operating on a collection of objects, such that for two objects x,y, PrhεF[h(x) = h(y)] = sim(x,y), where sim(x,y) ε [0,1] is some similarity function defined on the collection of objects. Such a scheme leads to a compact representation of objects so that similarity of objects can be estimated from their compact sketches, and also leads to efficient algorithms for approximate nearest neighbor search and clustering. Min-wise independent permutations provide an elegant construction of such a locality sensitive hashing scheme for a collection of subsets with the set similarity measure sim(A,B) = {\textbackslash}frac\{{\textbar}A ∩ B{\textbar}\}\{{\textbar}A ∪ B{\textbar}\}.(MATH) We show that rounding algorithms for LPs and SDPs used in the context of approximation algorithms can be viewed as locality sensitive hashing schemes for several interesting collections of objects. Based on this insight, we construct new locality sensitive hashing schemes for:A collection of vectors with the distance between → {\textbackslash}over u and → {\textbackslash}over v measured by Ø(→ {\textbackslash}over u, → {\textbackslash}over v)/π, where Ø(→ {\textbackslash}over u, → {\textbackslash}over v) is the angle between → {\textbackslash}over u) and → {\textbackslash}over v). This yields a sketching scheme for estimating the cosine similarity measure between two vectors, as well as a simple alternative to minwise independent permutations for estimating set similarity.A collection of distributions on n points in a metric space, with distance between distributions measured by the Earth Mover Distance (EMD), (a popular distance measure in graphics and vision). Our hash functions map distributions to points in the metric space such that, for distributions P and Q, EMD(P,Q) ≤ Ehε{\textbackslash}F [d(h(P),h(Q))] ≤ O(log n log log n). EMD(P, Q).},
	urldate = {2024-07-10},
	booktitle = {Proceedings of the thiry-fourth annual {ACM} symposium on {Theory} of computing},
	publisher = {Association for Computing Machinery},
	author = {Charikar, Moses S.},
	month = may,
	year = {2002},
	pages = {380--388},
	file = {Charikar - Similarity Estimation Techniques from Rounding Alg.pdf:/home/timo/Zotero/storage/C2JSQNUC/Charikar - Similarity Estimation Techniques from Rounding Alg.pdf:application/pdf},
}

@inproceedings{oliver_tlsh_2013,
	title = {{TLSH} – {A} {Locality} {Sensitive} {Hash}},
	url = {https://ieeexplore.ieee.org/abstract/document/6754635},
	doi = {10.1109/CTC.2013.9},
	abstract = {Cryptographic hashes such as MD5 and SHA-1 are used for many data mining and security applications – they are used as an identifier for files and documents. However, if a single byte of a file is changed, then cryptographic hashes result in a completely different hash value. It would be very useful to work with hashes which identify that files were similar based on their hash values. The security field has proposed similarity digests, and the data mining community has proposed locality sensitive hashes. Some proposals include the Nilsimsa hash (a locality sensitive hash), Ssdeep and Sdhash (both Ssdeep and Sdhash are similarity digests). Here, we describe a new locality sensitive hashing scheme the TLSH. We provide algorithms for evaluating and comparing hash values and provide a reference to its open source code. We do an empirical evaluation of publically available similarity digest schemes. The empirical evaluation highlights significant problems with previously proposed schemes; the TLSH scheme does not suffer from the flaws identified.},
	urldate = {2024-07-10},
	booktitle = {2013 {Fourth} {Cybercrime} and {Trustworthy} {Computing} {Workshop}},
	author = {Oliver, Jonathan and Cheng, Chun and Chen, Yanggui},
	month = nov,
	year = {2013},
	keywords = {Arrays, Cryptography, data fingerprinting, Data mining, Electronic mail, fuzzy hashing, Hamming distance, Locality sensitive hash, Malware, Nilsimsa, Sdhash, similarity digests, Ssdeep, TLSH.},
	pages = {7--13},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/XGHFVT67/6754635.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/5K29UURI/Oliver et al. - 2013 - TLSH – A Locality Sensitive Hash.pdf:application/pdf},
}

@inproceedings{fard_feedback-directed_2013,
	address = {Pasadena, CA, USA},
	title = {Feedback-directed exploration of web applications to derive test models},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-4799-2366-3},
	url = {https://ieeexplore.ieee.org/document/6698880/},
	doi = {10.1109/ISSRE.2013.6698880},
	abstract = {Dynamic exploration techniques play a signiﬁcant role in automated web application testing and analysis. However, a general web application crawler that exhaustively explores the states can become mired in limited speciﬁc regions of the web application, yielding poor functionality coverage. In this paper, we propose a feedback-directed web application exploration technique to derive test models. While exploring, our approach dynamically measures and applies a combination of code coverage impact, navigational diversity, and structural diversity, to decide a-priori (1) which state should be expanded, and (2) which event should be exercised next to maximize the overall coverage, while minimizing the size of the test model. Our approach is implemented in a tool called FEEDEX. We have empirically evaluated the efﬁcacy of FEEDEX using six web applications. The results show that our technique is successful in yielding higher coverage while reducing the size of the test model, compared to classical exhaustive techniques such as depth-ﬁrst, breadth-ﬁrst, and random exploration.},
	language = {en},
	urldate = {2024-07-10},
	booktitle = {2013 {IEEE} 24th {International} {Symposium} on {Software} {Reliability} {Engineering} ({ISSRE})},
	publisher = {IEEE},
	author = {Fard, Amin Milani and Mesbah, Ali},
	month = nov,
	year = {2013},
	pages = {278--287},
	file = {Fard and Mesbah - 2013 - Feedback-directed exploration of web applications .pdf:/home/timo/Zotero/storage/VEX79X47/Fard and Mesbah - 2013 - Feedback-directed exploration of web applications .pdf:application/pdf},
}

@article{pawlik_efficient_2015,
	title = {Efficient {Computation} of the {Tree} {Edit} {Distance}},
	volume = {40},
	issn = {0362-5915},
	url = {https://doi.org/10.1145/2699485},
	doi = {10.1145/2699485},
	abstract = {We consider the classical tree edit distance between ordered labelled trees, which is defined as the minimum-cost sequence of node edit operations that transform one tree into another. The state-of-the-art solutions for the tree edit distance are not satisfactory. The main competitors in the field either have optimal worst-case complexity but the worst case happens frequently, or they are very efficient for some tree shapes but degenerate for others. This leads to unpredictable and often infeasible runtimes. There is no obvious way to choose between the algorithms.In this article we present RTED, a robust tree edit distance algorithm. The asymptotic complexity of our algorithm is smaller than or equal to the complexity of the best competitors for any input instance, that is, our algorithm is both efficient and worst-case optimal. This is achieved by computing a dynamic decomposition strategy that depends on the input trees. RTED is shown optimal among all algorithms that use LRH (left-right-heavy) strategies, which include RTED and the fastest tree edit distance algorithms presented in literature. In our experiments on synthetic and real-world data we empirically evaluate our solution and compare it to the state-of-the-art.},
	number = {1},
	urldate = {2024-07-10},
	journal = {ACM Trans. Database Syst.},
	author = {Pawlik, Mateusz and Augsten, Nikolaus},
	month = mar,
	year = {2015},
	pages = {3:1--3:40},
	file = {Pawlik and Augsten - 2015 - Efficient Computation of the Tree Edit Distance.pdf:/home/timo/Zotero/storage/PUQG64SI/Pawlik and Augsten - 2015 - Efficient Computation of the Tree Edit Distance.pdf:application/pdf},
}

@article{zauner_implementation_nodate,
	title = {Implementation and {Benchmarking} of {Perceptual} {Image} {Hash} {Functions}},
	language = {en},
	author = {Zauner, Christoph},
	file = {Zauner - Implementation and Benchmarking of Perceptual Imag.pdf:/home/timo/Zotero/storage/CVVWYPTZ/Zauner - Implementation and Benchmarking of Perceptual Imag.pdf:application/pdf},
}

@misc{noauthor_block_nodate,
	title = {Block {Mean} {Value} {Based} {Image} {Perceptual} {Hashing} {\textbar} {IEEE} {Conference} {Publication} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/abstract/document/4041692},
	urldate = {2024-07-10},
}

@inproceedings{yang_block_2006,
	title = {Block {Mean} {Value} {Based} {Image} {Perceptual} {Hashing}},
	url = {https://ieeexplore.ieee.org/document/4041692/?arnumber=4041692},
	doi = {10.1109/IIH-MSP.2006.265125},
	abstract = {Image perceptual hashing has been proposed to identify or authenticate image contents in a robust way against distortions caused by compression, noise, common signal processing and geometrical modifications, while still holding a good discriminability for different ones in sense of human perception. We propose and compare four normalized block mean value based image perceptual hashing algorithms which demonstrate higher performances than other existing algorithms in robustness-anddiscriminalibility and simplicity for implementation. Overlapped blocking and rotation operations are employed to enhance the robustness to geometrical distortions. To evaluate the proposed algorithms robustness and discriminability, given fixed modifications, identification ratio is used; and given fixed content classification, receiver operating curves is obtained.},
	urldate = {2024-07-10},
	booktitle = {2006 {International} {Conference} on {Intelligent} {Information} {Hiding} and {Multimedia}},
	author = {Yang, Bian and Gu, Fan and Niu, Xiamu},
	month = dec,
	year = {2006},
	keywords = {Cryptography, Computational complexity, Computer science, Fingerprint recognition, Fourier transforms, Marine technology, Noise robustness, Sea measurements, Signal processing algorithms, Tiles},
	pages = {167--172},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/T3P9XZWT/4041692.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/YPCCTU2K/Yang et al. - 2006 - Block Mean Value Based Image Perceptual Hashing.pdf:application/pdf},
}

@inproceedings{swain_indexing_1992,
	address = {Berlin, Heidelberg},
	title = {Indexing via {Color} {Histograms}},
	isbn = {978-3-642-77225-2},
	doi = {10.1007/978-3-642-77225-2_13},
	abstract = {The color spectrum of multicolored objects provides a a robust, efficient cue for indexing into a large database of models. This paper shows color histograms to be stable object representations over change in view, and demonstrates they can differentiate among a large number of objects. It introduces a technique called Histogram Intersection for matching model and image histograms and a fast incremental version of Histogram Intersection that allows real-time indexing into a large database of stored models using standard vision hardware. Color can also be used to search for the location of an object. An algorithm called Histogram, Backprojection performs this task efficiently in crowded scenes.},
	language = {en},
	booktitle = {Active {Perception} and {Robot} {Vision}},
	publisher = {Springer},
	author = {Swain, Michael J. and Ballard, Dana H.},
	editor = {Sood, Arun K. and Wechsler, Harry},
	year = {1992},
	pages = {261--273},
}

@article{yee_spatiotemporal_2001,
	title = {Spatiotemporal sensitivity and visual attention for efficient rendering of dynamic environments},
	volume = {20},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/383745.383748},
	doi = {10.1145/383745.383748},
	abstract = {We present a method to accelerate global illumination computation in prerendered animations by taking advantage of limitations of the human visual system. A spatiotemporal error tolerance map, constructed from psychophysical data based on velocity dependent contrast sensitivity, is used to accelerate rendering. The error map is augmented by a model of visual attention in order to account for the tracking behavior of the eye. Perceptual acceleration combined with good sampling protocols provide a global illumination solution feasible for use in animation. Results indicate an order of magnitude improvement in computational speed.},
	number = {1},
	urldate = {2024-07-10},
	journal = {ACM Trans. Graph.},
	author = {Yee, Hector and Pattanaik, Sumanita and Greenberg, Donald P.},
	month = jan,
	year = {2001},
	pages = {39--65},
	file = {Submitted Version:/home/timo/Zotero/storage/BILFFSF6/Yee et al. - 2001 - Spatiotemporal sensitivity and visual attention fo.pdf:application/pdf;Yee et al. - 2001 - Spatiotemporal sensitivity and visual attention fo.pdf:/home/timo/Zotero/storage/PQHRW3W5/Yee et al. - 2001 - Spatiotemporal sensitivity and visual attention fo.pdf:application/pdf},
}

@article{wang_image_2004,
	title = {Image quality assessment: from error visibility to structural similarity},
	volume = {13},
	issn = {1941-0042},
	shorttitle = {Image quality assessment},
	url = {https://ieeexplore.ieee.org/abstract/document/1284395},
	doi = {10.1109/TIP.2003.819861},
	abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.},
	number = {4},
	urldate = {2024-07-10},
	journal = {IEEE Transactions on Image Processing},
	author = {Wang, Zhou and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
	month = apr,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Data mining, Degradation, Humans, Image quality, Indexes, Layout, Quality assessment, Transform coding, Visual perception, Visual system},
	pages = {600--612},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/JYHY2H99/1284395.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/BMZHUXXE/Wang et al. - 2004 - Image quality assessment from error visibility to.pdf:application/pdf},
}

@inproceedings{lowe_object_1999,
	title = {Object recognition from local scale-invariant features},
	volume = {2},
	url = {https://ieeexplore.ieee.org/abstract/document/790410},
	doi = {10.1109/ICCV.1999.790410},
	abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.},
	urldate = {2024-07-10},
	booktitle = {Proceedings of the {Seventh} {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Lowe, D.G.},
	month = sep,
	year = {1999},
	keywords = {Computer science, Layout, Electrical capacitance tomography, Filters, Image recognition, Lighting, Neurons, Object recognition, Programmable logic arrays, Reactive power},
	pages = {1150--1157 vol.2},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/SE6YKUXM/790410.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/726WH999/Lowe - 1999 - Object recognition from local scale-invariant feat.pdf:application/pdf},
}

@article{levenshtein_levenshtein_1966,
	title = {Levenshtein, {Vladimir} {I}. "{Binary} codes capable of correcting deletions, insertions, and reversals.},
	volume = {10},
	url = {https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf},
	number = {8},
	urldate = {2024-07-10},
	journal = {Soviet physics doklady},
	author = {Levenshtein, Vladimir I.},
	year = {1966},
	pages = {707--710},
	file = {Levenshtein1966a.pdf:/home/timo/Zotero/storage/I4SK9VKD/Levenshtein1966a.pdf:application/pdf},
}

@misc{noauthor_web_2024,
	title = {Web {Components} - {Web} {APIs} {\textbar} {MDN}},
	url = {https://developer.mozilla.org/en-US/docs/Web/API/Web_components},
	abstract = {Web Components is a suite of different technologies allowing you to create reusable custom elements — with their functionality encapsulated away from the rest of your code — and utilize them in your web apps.},
	language = {en-US},
	urldate = {2024-07-10},
	month = jul,
	year = {2024},
	file = {Snapshot:/home/timo/Zotero/storage/WRUWUCWM/Web_components.html:text/html},
}

@article{vale_twenty-eight_2016,
	title = {Twenty-eight years of component-based software engineering},
	volume = {111},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121215002095},
	doi = {10.1016/j.jss.2015.09.019},
	abstract = {The idea of developing software components was envisioned more than forty years ago. In the past two decades, Component-Based Software Engineering (CBSE) has emerged as a distinguishable approach in software engineering, and it has attracted the attention of many researchers, which has led to many results being published in the research literature. There is a huge amount of knowledge encapsulated in conferences and journals targeting this area, but a systematic analysis of that knowledge is missing. For this reason, we aim to investigate the state-of-the-art of the CBSE area through a detailed literature review. To do this, 1231 studies dating from 1984 to 2012 were analyzed. Using the available evidence, this paper addresses five dimensions of CBSE: main objectives, research topics, application domains, research intensity and applied research methods. The main objectives found were to increase productivity, save costs and improve quality. The most addressed application domains are homogeneously divided between commercial-off-the-shelf (COTS), distributed and embedded systems. Intensity of research showed a considerable increase in the last fourteen years. In addition to the analysis, this paper also synthesizes the available evidence, identifies open issues and points out areas that call for further research.},
	urldate = {2024-07-10},
	journal = {Journal of Systems and Software},
	author = {Vale, Tassio and Crnkovic, Ivica and de Almeida, Eduardo Santana and Silveira Neto, Paulo Anselmo da Mota and Cavalcanti, Yguaratã Cerqueira and Meira, Silvio Romero de Lemos},
	month = jan,
	year = {2016},
	keywords = {Component-based software development, Component-based software engineering, Software component, Systematic mapping study},
	pages = {128--148},
	file = {ScienceDirect Snapshot:/home/timo/Zotero/storage/7DSH85RU/S0164121215002095.html:text/html;Vale et al. - 2016 - Twenty-eight years of component-based software eng.pdf:/home/timo/Zotero/storage/NJJZDLDB/Vale et al. - 2016 - Twenty-eight years of component-based software eng.pdf:application/pdf},
}

@article{krznar_current_2016,
	title = {Current usage of {Component} based {Principles} for {Developing} {Web} {Applications} with {Frameworks}: {A} {Literature} {Review}},
	volume = {14},
	issn = {1334-4676, 1334-4684},
	shorttitle = {Current usage of {Component} based {Principles} for {Developing} {Web} {Applications} with {Frameworks}},
	url = {http://indecs.eu/index.php?s=x&y=2016&p=253-276},
	doi = {10.7906/indecs.14.2.14},
	language = {en},
	number = {2},
	urldate = {2024-07-10},
	journal = {Interdisciplinary Description of Complex Systems},
	author = {Krznar, Matija and Svogor, Ivan},
	year = {2016},
	pages = {253--276},
	file = {Full Text:/home/timo/Zotero/storage/FEB4BDHX/Krznar and Svogor - 2016 - Current usage of Component based Principles for De.pdf:application/pdf},
}

@article{pawlik_tree_2016,
	title = {Tree edit distance: {Robust} and memory-efficient},
	volume = {56},
	issn = {0306-4379},
	shorttitle = {Tree edit distance},
	url = {https://www.sciencedirect.com/science/article/pii/S0306437915001611},
	doi = {10.1016/j.is.2015.08.004},
	abstract = {Hierarchical data are often modelled as trees. An interesting query identifies pairs of similar trees. The standard approach to tree similarity is the tree edit distance, which has successfully been applied in a wide range of applications. In terms of runtime, the state-of-the-art algorithm for the tree edit distance is RTED, which is guaranteed to be fast independent of the tree shape. Unfortunately, this algorithm requires up to twice the memory of its competitors. The memory is quadratic in the tree size and is a bottleneck for the tree edit distance computation. In this paper we present a new, memory efficient algorithm for the tree edit distance, AP-TED (All Path Tree Edit Distance). Our algorithm runs at least as fast as RTED without trading in memory efficiency. This is achieved by releasing memory early during the first step of the algorithm, which computes a decomposition strategy for the actual distance computation. We show the correctness of our approach and prove an upper bound for the memory usage. The strategy computed by AP-TED is optimal in the class of all-path strategies, which subsumes the class of LRH strategies used in RTED. We further present the AP-TED+ algorithm, which requires less computational effort for very small subtrees and improves the runtime of the distance computation. Our experimental evaluation confirms the low memory requirements and the runtime efficiency of our approach.},
	urldate = {2024-07-10},
	journal = {Information Systems},
	author = {Pawlik, Mateusz and Augsten, Nikolaus},
	month = mar,
	year = {2016},
	keywords = {Approximate matching, Similarity search, Tree edit distance},
	pages = {157--173},
	file = {Pawlik and Augsten - 2016 - Tree edit distance Robust and memory-efficient.pdf:/home/timo/Zotero/storage/I64BL9X2/Pawlik and Augsten - 2016 - Tree edit distance Robust and memory-efficient.pdf:application/pdf;ScienceDirect Snapshot:/home/timo/Zotero/storage/KZWSPALS/S0306437915001611.html:text/html},
}

@article{cai_vips_2003,
	title = {{VIPS}: a {Vision}-based {Page} {Segmentation} {Algorithm}},
	shorttitle = {{VIPS}},
	url = {https://www.microsoft.com/en-us/research/publication/vips-a-vision-based-page-segmentation-algorithm/},
	abstract = {A new web content structure analysis based on visual representation is proposed in this paper. Many web applications such as information retrieval, information extraction and automatic page adaptation can benefit from this structure. This paper presents an automatic top-down, tag-tree independent approach to detect web content structure. It simulates how a user understands web layout […]},
	language = {en-US},
	urldate = {2024-07-10},
	author = {Cai, Deng and Yu, Shipeng and Wen, Ji-Rong and Ma, Wei-Ying},
	month = nov,
	year = {2003},
	file = {Full Text PDF:/home/timo/Zotero/storage/733296HN/Cai et al. - 2003 - VIPS a Vision-based Page Segmentation Algorithm.pdf:application/pdf},
}

@incollection{ricca_chapter_2019,
	title = {Chapter {Three} - {Three} {Open} {Problems} in the {Context} of {E2E} {Web} {Testing} and a {Vision}: {NEONATE}},
	volume = {113},
	shorttitle = {Chapter {Three} - {Three} {Open} {Problems} in the {Context} of {E2E} {Web} {Testing} and a {Vision}},
	url = {https://www.sciencedirect.com/science/article/pii/S0065245818300652},
	abstract = {Web applications are critical assets of our society and thus assuring their quality is of undeniable importance. Despite the advances in software testing, the ever-increasing technological complexity of these applications makes it difficult to prevent errors. In this work, we provide a thorough description of the three open problems hindering web test automation: fragility problem, strong coupling and low cohesion problem, and incompleteness problem. We conjecture that a major breakthrough in test automation is needed, because the problems are closely correlated, and hence need to be attacked together rather than separately. To this aim, we describe Neonate, a novel integrated testing environment specifically designed to empower the web tester. Our utmost purpose is to make the research community aware of the existence of the three problems and their correlation, so that more research effort can be directed in providing solutions and tools to advance the state of the art of web test automation.},
	urldate = {2024-07-12},
	booktitle = {Advances in {Computers}},
	publisher = {Elsevier},
	author = {Ricca, Filippo and Leotta, Maurizio and Stocco, Andrea},
	editor = {Memon, Atif M.},
	month = jan,
	year = {2019},
	doi = {10.1016/bs.adcom.2018.10.005},
	keywords = {Development effort, End-to-end testing, Maintenance effort, Page object pattern, Reverse engineering, Robust locators, Selenium, Web testing},
	pages = {89--133},
	file = {Ricca et al. - 2019 - Three Open Problems in the Context of E2E Web Test.pdf:/home/timo/Zotero/storage/5BGV2WWX/Ricca et al. - 2019 - Three Open Problems in the Context of E2E Web Test.pdf:application/pdf;ScienceDirect Snapshot:/home/timo/Zotero/storage/B3N9UNYD/S0065245818300652.html:text/html},
}

@inproceedings{manku_detecting_2007,
	address = {Banff Alberta Canada},
	title = {Detecting near-duplicates for web crawling},
	isbn = {978-1-59593-654-7},
	url = {https://dl.acm.org/doi/10.1145/1242572.1242592},
	doi = {10.1145/1242572.1242592},
	abstract = {Near-duplicate web documents are abundant. Two such documents diﬀer from each other in a very small portion that displays advertisements, for example. Such diﬀerences are irrelevant for web search. So the quality of a web crawler increases if it can assess whether a newly crawled web page is a near-duplicate of a previously crawled web page or not. In the course of developing a near-duplicate detection system for a multi-billion page repository, we make two research contributions. First, we demonstrate that Charikar’s ﬁngerprinting technique is appropriate for this goal. Second, we present an algorithmic technique for identifying existing f bit ﬁngerprints that diﬀer from a given ﬁngerprint in at most k bit-positions, for small k. Our technique is useful for both online queries (single ﬁngerprints) and batch queries (multiple ﬁngerprints). Experimental evaluation over real data conﬁrms the practicality of our design.},
	language = {en},
	urldate = {2024-07-12},
	booktitle = {Proceedings of the 16th international conference on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Manku, Gurmeet Singh and Jain, Arvind and Das Sarma, Anish},
	month = may,
	year = {2007},
	pages = {141--150},
	file = {Manku et al. - 2007 - Detecting near-duplicates for web crawling.pdf:/home/timo/Zotero/storage/QS7Y6FM5/Manku et al. - 2007 - Detecting near-duplicates for web crawling.pdf:application/pdf},
}

@inproceedings{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	urldate = {2024-07-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	pages = {1877--1901},
	file = {Full Text PDF:/home/timo/Zotero/storage/NI5K9KMV/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
}

@misc{touvron_llama_2023,
	title = {{LLaMA}: {Open} and {Efficient} {Foundation} {Language} {Models}},
	shorttitle = {{LLaMA}},
	url = {http://arxiv.org/abs/2302.13971},
	doi = {10.48550/arXiv.2302.13971},
	abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
	urldate = {2024-07-13},
	publisher = {arXiv},
	author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13971 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/timo/Zotero/storage/XJZIME9Z/Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Mode.pdf:application/pdf;arXiv.org Snapshot:/home/timo/Zotero/storage/IYVPZTPS/2302.html:text/html},
}

@misc{openai_gpt-4_2024,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	urldate = {2024-07-13},
	publisher = {arXiv},
	author = {OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and Bernadett-Shapiro, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Simón Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and Gontijo-Lopes, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, Łukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, Łukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney, Scott Mayer and McLeavey, Christine and McMillan, Paul and McNeil, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and Mély, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cerón and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
	month = mar,
	year = {2024},
	note = {arXiv:2303.08774 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/timo/Zotero/storage/BVP64W9J/OpenAI et al. - 2024 - GPT-4 Technical Report.pdf:application/pdf;arXiv.org Snapshot:/home/timo/Zotero/storage/MCEWVH5N/2303.html:text/html},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	urldate = {2024-07-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Ł ukasz and Polosukhin, Illia},
	year = {2017},
	file = {Full Text PDF:/home/timo/Zotero/storage/ABKBSNR6/Vaswani et al. - 2017 - Attention is All you Need.pdf:application/pdf},
}

@misc{schick_its_2021,
	title = {It's {Not} {Just} {Size} {That} {Matters}: {Small} {Language} {Models} {Are} {Also} {Few}-{Shot} {Learners}},
	shorttitle = {It's {Not} {Just} {Size} {That} {Matters}},
	url = {http://arxiv.org/abs/2009.07118},
	doi = {10.48550/arXiv.2009.07118},
	abstract = {When scaled to hundreds of billions of parameters, pretrained language models such as GPT-3 (Brown et al., 2020) achieve remarkable few-shot performance. However, enormous amounts of compute are required for training and applying such big models, resulting in a large carbon footprint and making it difficult for researchers and practitioners to use them. We show that performance similar to GPT-3 can be obtained with language models that are much "greener" in that their parameter count is several orders of magnitude smaller. This is achieved by converting textual inputs into cloze questions that contain a task description, combined with gradient-based optimization; exploiting unlabeled data gives further improvements. We identify key factors required for successful natural language understanding with small language models.},
	urldate = {2024-07-13},
	publisher = {arXiv},
	author = {Schick, Timo and Schütze, Hinrich},
	month = apr,
	year = {2021},
	note = {arXiv:2009.07118 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/timo/Zotero/storage/H9A66NTS/Schick and Schütze - 2021 - It's Not Just Size That Matters Small Language Mo.pdf:application/pdf;arXiv.org Snapshot:/home/timo/Zotero/storage/ZGX57TAB/2009.html:text/html},
}

@misc{gholami_generative_2023,
	title = {Do {Generative} {Large} {Language} {Models} need billions of parameters?},
	url = {http://arxiv.org/abs/2309.06589},
	doi = {10.48550/arXiv.2309.06589},
	abstract = {This paper presents novel systems and methodologies for the development of efficient large language models (LLMs). It explores the trade-offs between model size, performance, and computational resources, with the aim of maximizing the efficiency of these AI systems. The research explores novel methods that allow different parts of the model to share parameters, reducing the total number of unique parameters required. This approach ensures that the model remains compact without sacrificing its ability to learn and represent complex language structures. This study provides valuable insights and tools for creating more efficient and effective LLMs, contributing to a more sustainable and accessible future for AI language modeling.},
	urldate = {2024-07-13},
	publisher = {arXiv},
	author = {Gholami, Sia and Omar, Marwan},
	month = sep,
	year = {2023},
	note = {arXiv:2309.06589 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/timo/Zotero/storage/4UMQ8Q89/Gholami and Omar - 2023 - Do Generative Large Language Models need billions .pdf:application/pdf;arXiv.org Snapshot:/home/timo/Zotero/storage/LWSSQ5BP/2309.html:text/html},
}

@misc{noauthor_selenium_nodate,
	title = {Selenium},
	url = {https://www.selenium.dev/},
	abstract = {Selenium automates browsers. That's it! What you do with that power is entirely up to you.
Primarily it is for automating web applications for testing purposes, but is certainly not limited to just that. Boring web-based administration tasks can (and should) also be automated as well. Getting Started Selenium WebDriver Selenium WebDriver If you want to create robust, browser-based regression automation suites and tests, scale and distribute scripts across many environments, then you want to use Selenium WebDriver, a collection of language specific bindings to drive a browser - the way it is meant to be driven.},
	language = {en},
	urldate = {2024-07-14},
	journal = {Selenium},
}

@inproceedings{chaini_test_2015,
	title = {Test script execution and effective result analysis in hybrid test automation framework},
	url = {https://ieeexplore.ieee.org/abstract/document/7164698},
	doi = {10.1109/ICACEA.2015.7164698},
	abstract = {In today's fast moving world, it is a challenge to continuously maintain, improve the quality and efficiency of software systems development. In many software projects, testing is neglected because of time or cost constraint which leads to lack of product quality. Test automation reduces the future maintenance efforts and cost significantly. Automated test suite can run fast and frequently, which is cost-effective for software products with a long maintenance life. It also increases the test coverage with very low cost. The Main objective of the paper is to find out the process for test script design and execution as well as failure analysis of the scripts. In this paper types of failures has been defined as per the defined hybrid framework. Quality of test cases is determined by their ability to uncover as many errors as possible in the web application. After execution, for fail test scripts our method can find out whether the failure is a valid issue or a false positive. There are many types of failures which come under false positive.},
	urldate = {2024-07-14},
	booktitle = {2015 {International} {Conference} on {Advances} in {Computer} {Engineering} and {Applications}},
	author = {Chaini, Hari Sankar and Pradhan, Sateesh Kumar},
	month = mar,
	year = {2015},
	keywords = {Application under test, Automation, Computers, Context, Failure analysis, Failure Analysis, Hybrid Framework, Regression Testing, Robustness, Test script, Time factors, Webapplication},
	pages = {214--217},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/HYMZCW9M/7164698.html:text/html},
}

@inproceedings{chaini_test_2015-1,
	title = {Test script execution and effective result analysis in hybrid test automation framework},
	url = {https://ieeexplore.ieee.org/document/7164698/?arnumber=7164698},
	doi = {10.1109/ICACEA.2015.7164698},
	abstract = {In today's fast moving world, it is a challenge to continuously maintain, improve the quality and efficiency of software systems development. In many software projects, testing is neglected because of time or cost constraint which leads to lack of product quality. Test automation reduces the future maintenance efforts and cost significantly. Automated test suite can run fast and frequently, which is cost-effective for software products with a long maintenance life. It also increases the test coverage with very low cost. The Main objective of the paper is to find out the process for test script design and execution as well as failure analysis of the scripts. In this paper types of failures has been defined as per the defined hybrid framework. Quality of test cases is determined by their ability to uncover as many errors as possible in the web application. After execution, for fail test scripts our method can find out whether the failure is a valid issue or a false positive. There are many types of failures which come under false positive.},
	urldate = {2024-07-14},
	booktitle = {2015 {International} {Conference} on {Advances} in {Computer} {Engineering} and {Applications}},
	author = {Chaini, Hari Sankar and Pradhan, Sateesh Kumar},
	month = mar,
	year = {2015},
	keywords = {Application under test, Automation, Computers, Context, Failure analysis, Failure Analysis, Hybrid Framework, Regression Testing, Robustness, Test script, Time factors, Webapplication},
	pages = {214--217},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/TRJCB4SA/7164698.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/K6UF6DDI/Chaini and Pradhan - 2015 - Test script execution and effective result analysi.pdf:application/pdf},
}

@incollection{candea_automated_2019,
	address = {Cham},
	title = {Automated {Software} {Test} {Generation}: {Some} {Challenges}, {Solutions}, and {Recent} {Advances}},
	isbn = {978-3-319-91908-9},
	shorttitle = {Automated {Software} {Test} {Generation}},
	url = {https://doi.org/10.1007/978-3-319-91908-9_24},
	abstract = {The automation of software testing promises to delegate to machines what is otherwise the most labor-intensive and expensive part of software development. The past decade has seen a resurgence in research interest for this problem, bringing about significant progress. In this article, we provide an overview of automated test generation for software, and then discuss recent developments that have had significant impact on real-life software.},
	language = {en},
	urldate = {2024-07-14},
	booktitle = {Computing and {Software} {Science}: {State} of the {Art} and {Perspectives}},
	publisher = {Springer International Publishing},
	author = {Candea, George and Godefroid, Patrice},
	editor = {Steffen, Bernhard and Woeginger, Gerhard},
	year = {2019},
	doi = {10.1007/978-3-319-91908-9_24},
	keywords = {Program analysis, Software testing, Symbolic execution},
	pages = {505--531},
	file = {Full Text PDF:/home/timo/Zotero/storage/WZIMIEFX/Candea and Godefroid - 2019 - Automated Software Test Generation Some Challenge.pdf:application/pdf},
}

@inproceedings{ramya_testing_2017,
	title = {Testing using selenium web driver},
	url = {https://ieeexplore.ieee.org/abstract/document/8117878},
	doi = {10.1109/ICECCT.2017.8117878},
	abstract = {Software testing is considered to be the most important step in Software Development Life Cycle. The main objective of the testing process is to compare the obtained results with those of expected by the end user of the software. Test Automation simplifies the work of tester by automating the execution of test scripts with the use of a special software. This paper focuses on the use of Selenium Webdriver to test a web application and to demonstrate the use of this tool in combination with other tools like the Maven, TestNG, etc., for more easier approach to testing and to improve the quality of testing process.},
	urldate = {2024-07-14},
	booktitle = {2017 {Second} {International} {Conference} on {Electrical}, {Computer} and {Communication} {Technologies} ({ICECCT})},
	author = {Ramya, Paruchuri and Sindhura, Vemuri and Sagar, P. Vidya},
	month = feb,
	year = {2017},
	keywords = {Selenium, Browsers, Law, Maven, Selenium Web driver, Software, Testing, TestNG, Tools},
	pages = {1--7},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/9TG3LUGJ/8117878.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/RQ5RVZSH/Ramya et al. - 2017 - Testing using selenium web driver.pdf:application/pdf},
}

@misc{noauthor_ms_nodate,
	title = {{MS} {Quarterly} {Earnings} {Q2} 2024},
	url = {https://medius.microsoft.com/Embed/video-nc/9bf7bb54-6cfb-4353-9cf1-740cf18bf22a?r=996167830985},
	abstract = {Video publishing platform},
	language = {en},
	urldate = {2024-07-14},
	journal = {Medius},
}

@article{memon_regression_2003,
	title = {Regression testing of {GUIs}},
	abstract = {Although graphical user interfaces (GUIs) constitute a large part of the software being developed today and are typically created using rapid prototyping, there are no eﬀective regression testing techniques for GUIs. The needs of GUI regression testing diﬀer from those of traditional software. When the structure of a GUI is modiﬁed, test cases from the original GUI are either reusable or unusable on the modiﬁed GUI. Since GUI test case generation is expensive, our goal is to make the unusable test cases usable. The idea of reusing these unusable (a.k.a. obsolete) test cases has not been explored before. In this paper, we show that for GUIs, the unusability of a large number of test cases is a serious problem. We present a novel GUI regression testing technique that ﬁrst automatically determines the usable and unusable test cases from a test suite after a GUI modiﬁcation. It then determines which of the unusable test cases can be repaired so they can execute on the modiﬁed GUI. The last step is to repair the test cases. Our technique is integrated into a GUI testing framework that, given a test case, automatically executes it on the GUI. We implemented our regression testing technique and demonstrate for two case studies that our approach is eﬀective in that many of the test cases can be repaired, and is practical in terms of its time performance.},
	language = {en},
	author = {Memon, Atif M and Soffa, Mary Lou},
	year = {2003},
	file = {Memon and Soffa - Regression testing of GUIs.pdf:/home/timo/Zotero/storage/7YD3T6YE/Memon and Soffa - Regression testing of GUIs.pdf:application/pdf},
}

@inproceedings{grechanik_maintaining_2009,
	title = {Maintaining and evolving {GUI}-directed test scripts},
	url = {https://ieeexplore.ieee.org/abstract/document/5070540},
	doi = {10.1109/ICSE.2009.5070540},
	abstract = {Since manual black-box testing of GUI-based applications (GAPs) is tedious and laborious, test engineers create test scripts to automate the testing process. These test scripts interact with GAPs by performing actions on their GUI objects. An extra effort that test engineers put in writing test scripts is paid off when these scripts are run repeatedly. Unfortunately, releasing new versions of GAPs with modified GUIs breaks their corresponding test scripts thereby obliterating benefits of test automation. We offer a novel approach for maintaining and evolving test scripts so that they can test new versions of their respective GAPs. We built a tool to implement our approach, and we conducted a case study with forty five professional programmers and test engineers to evaluate this tool. The results show with strong statistical significance that users find more failures and report fewer false positives (p {\textless} 0.02) in test scripts with our tool than with a flagship industry product and a baseline manual approach. Our tool is lightweight and it takes less than eight seconds to analyze approximately 1KLOC of test scripts.},
	urldate = {2024-07-14},
	booktitle = {2009 {IEEE} 31st {International} {Conference} on {Software} {Engineering}},
	author = {Grechanik, Mark and Xie, Qing and Fu, Chen},
	month = may,
	year = {2009},
	note = {ISSN: 1558-1225},
	keywords = {Automation, Automatic testing, Costs, Graphical user interfaces, Logic testing, Maintenance engineering, Manuals, Performance evaluation, Runtime, Writing},
	pages = {408--418},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/KMRZNCEA/5070540.html:text/html},
}

@inproceedings{grechanik_maintaining_2009-1,
	title = {Maintaining and evolving {GUI}-directed test scripts},
	url = {https://ieeexplore.ieee.org/document/5070540/?arnumber=5070540},
	doi = {10.1109/ICSE.2009.5070540},
	abstract = {Since manual black-box testing of GUI-based applications (GAPs) is tedious and laborious, test engineers create test scripts to automate the testing process. These test scripts interact with GAPs by performing actions on their GUI objects. An extra effort that test engineers put in writing test scripts is paid off when these scripts are run repeatedly. Unfortunately, releasing new versions of GAPs with modified GUIs breaks their corresponding test scripts thereby obliterating benefits of test automation. We offer a novel approach for maintaining and evolving test scripts so that they can test new versions of their respective GAPs. We built a tool to implement our approach, and we conducted a case study with forty five professional programmers and test engineers to evaluate this tool. The results show with strong statistical significance that users find more failures and report fewer false positives (p {\textless} 0.02) in test scripts with our tool than with a flagship industry product and a baseline manual approach. Our tool is lightweight and it takes less than eight seconds to analyze approximately 1KLOC of test scripts.},
	urldate = {2024-07-14},
	booktitle = {2009 {IEEE} 31st {International} {Conference} on {Software} {Engineering}},
	author = {Grechanik, Mark and Xie, Qing and Fu, Chen},
	month = may,
	year = {2009},
	note = {ISSN: 1558-1225},
	keywords = {Automation, Automatic testing, Costs, Graphical user interfaces, Logic testing, Maintenance engineering, Manuals, Performance evaluation, Runtime, Writing},
	pages = {408--418},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/6TIDZVML/5070540.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/CCLREYH2/Grechanik et al. - 2009 - Maintaining and evolving GUI-directed test scripts.pdf:application/pdf},
}

@inproceedings{thummalapenta_guided_2013,
	title = {Guided test generation for web applications},
	url = {https://ieeexplore.ieee.org/document/6606562/?arnumber=6606562},
	doi = {10.1109/ICSE.2013.6606562},
	abstract = {We focus on functional testing of enterprise applications with the goal of exercising an application's interesting behaviors by driving it from its user interface. The difficulty in doing this is focusing on the interesting behaviors among an unbounded number of behaviors. We present a new technique for automatically generating tests that drive a web-based application along interesting behaviors, where the interesting behavior is specified in the form of “business rules.” Business rules are a general mechanism for describing business logic, access control, or even navigational properties of an application's GUI. Our technique is black box, in that it does not analyze the application's server-side implementation, but relies on directed crawling via the application's GUI. To handle the unbounded number of GUI states, the technique includes two phases. Phase 1 creates an abstract state-transition diagram using a relaxed notion of equivalence of GUI states without considering rules. Next, Phase 2 identifies rule-relevant abstract paths and refines those paths using a stricter notion of state equivalence. Our technique can be much more effective at covering business rules than an undirected technique, developed as an enhancement of an existing test-generation technique. Our experiments showed that the former was able to cover 92\% of the rules, compared to 52\% of the rules covered by the latter.},
	urldate = {2024-07-14},
	booktitle = {2013 35th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Thummalapenta, Suresh and Lakshmi, K. Vasanta and Sinha, Saurabh and Sinha, Nishant and Chandra, Satish},
	month = may,
	year = {2013},
	note = {ISSN: 1558-1225},
	keywords = {Testing, Graphical user interfaces, Manuals, Abstracts, Access control, Business, Navigation},
	pages = {162--171},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/HWRF6HNP/6606562.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/9YT867AD/Thummalapenta et al. - 2013 - Guided test generation for web applications.pdf:application/pdf},
}

@inproceedings{christophe_prevalence_2014,
	title = {Prevalence and {Maintenance} of {Automated} {Functional} {Tests} for {Web} {Applications}},
	url = {https://ieeexplore.ieee.org/document/6976080/?arnumber=6976080},
	doi = {10.1109/ICSME.2014.36},
	abstract = {Functional testing requires executing particular sequences of user actions. Test automation tools enable scripting user actions such that they can be repeated more easily. SELENIUM, for instance, enables testing Web applications through scripts that interact with a Web browser and assert properties about its observable state. However, little is known about how common such tests are in practice. We therefore present a cross-sectional quantitative study of the prevalence of SELENIUM-based tests among open-source Web applications, and of the extent to which such tests are used within individual applications. Automating functional tests also brings about the problem of maintaining test scripts. As the system under test evolves, its test scripts are bound to break. Even less is known about the way test scripts change over time. We therefore also present a longitudinal quantitative study of whether and for how long test scripts are maintained, as well as a longitudinal qualitative study of the kind of changes they undergo. To the former's end, we propose two new metrics based on whether a commit to the application's version repository touches a test file. To the latter's end, we propose to categorize the changes within each commit based on the elements of the test upon which they operate. As such, we are able to identify the elements of a test that are most prone to change.},
	urldate = {2024-07-14},
	booktitle = {2014 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution}},
	author = {Christophe, Laurent and Stevens, Reinout and De Roover, Coen and De Meuter, Wolfgang},
	month = sep,
	year = {2014},
	note = {ISSN: 1063-6773},
	keywords = {Selenium, Browsers, Testing, Graphical user interfaces, Maintenance engineering, Functional testing, Java, Measurement, Test automation},
	pages = {141--150},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/B9N32YLD/6976080.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/JUK5GC7M/Christophe et al. - 2014 - Prevalence and Maintenance of Automated Functional.pdf:application/pdf},
}

@article{ouyang_training_2022,
	title = {Training language models to follow instructions with human feedback},
	abstract = {Making language models bigger does not inherently make them better at following a user’s intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
	language = {en},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	month = mar,
	year = {2022},
	file = {Ouyang et al. - Training language models to follow instructions wi.pdf:/home/timo/Zotero/storage/WK2LTNYI/Ouyang et al. - Training language models to follow instructions wi.pdf:application/pdf},
}

@misc{ouyang_training_2022-1,
	title = {Training language models to follow instructions with human feedback},
	url = {http://arxiv.org/abs/2203.02155},
	doi = {10.48550/arXiv.2203.02155},
	abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
	urldate = {2024-07-19},
	publisher = {arXiv},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	month = mar,
	year = {2022},
	note = {arXiv:2203.02155 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/timo/Zotero/storage/7DY9PWA8/Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf:application/pdf;arXiv.org Snapshot:/home/timo/Zotero/storage/39TNI2K2/2203.html:text/html},
}

@article{zhou_large_2023,
	title = {{LARGE} {LANGUAGE} {MODELS} {ARE} {HUMAN}-{LEVEL} {PROMPT} {ENGINEERS}},
	language = {en},
	author = {Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris},
	year = {2023},
	file = {Zhou et al. - 2023 - LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGIN.pdf:/home/timo/Zotero/storage/4GIJL9EZ/Zhou et al. - 2023 - LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGIN.pdf:application/pdf},
}

@inproceedings{holmes_automating_2006,
	title = {Automating functional tests using {Selenium}},
	url = {https://ieeexplore.ieee.org/abstract/document/1667589},
	doi = {10.1109/AGILE.2006.19},
	abstract = {Ever in search of a silver bullet for automated functional testing for Web applications, many folks have turned to Selenium. Selenium is an open-source project for in-browser testing, originally developed by ThoughtWorks and now boasting an active community of developers and users. One of Selenium's stated goals is to become the de facto open-source replacement for proprietary tools such as WinRunner. Of particular interest to the agile community is that it offers the possibility of test-first design of Web applications, red-green signals for customer acceptance tests, and an automated regression test bed for the Web tier. This experience report describes the standard environment for testing with Selenium, as well as modifications we performed to incorporate our script pages into a wiki. It includes lessons we learned about continuous integration, script writing, and using the Selenium Recorder (renamed IDE). We also discuss how long it took to write and maintain the scripts in the iterative development environment, how close we came to covering all of the functional requirements with tests, how often the tests should be (and were) run, and whether additional automated functional testing below the GUI layer was still necessary and/or appropriate. While no silver bullet, Selenium has become a valuable addition to our agile testing toolkit, and is used on the majority of our Web application projects. It promises to become even more valuable as it gains widespread adoption and continues to be actively developed.},
	urldate = {2024-07-25},
	booktitle = {{AGILE} 2006 ({AGILE}'06)},
	author = {Holmes, A. and Kellogg, M.},
	month = jul,
	year = {2006},
	keywords = {Software testing, Automatic testing, Graphical user interfaces, Performance evaluation, Writing, Java, Application software, Open source software, Signal design, Silver},
	pages = {6 pp.--275},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/NJAG3ZMV/1667589.html:text/html},
}

@misc{noauthor_technology_nodate,
	title = {Technology {\textbar} 2024 {Stack} {Overflow} {Developer} {Survey}},
	url = {https://survey.stackoverflow.co/2024/technology#most-popular-technologies-webframe-prof},
	language = {en},
	urldate = {2024-07-25},
	file = {Snapshot:/home/timo/Zotero/storage/2GSIGWFD/technology.html:text/html},
}

@misc{sclar_quantifying_2024,
	title = {Quantifying {Language} {Models}' {Sensitivity} to {Spurious} {Features} in {Prompt} {Design} or: {How} {I} learned to start worrying about prompt formatting},
	shorttitle = {Quantifying {Language} {Models}' {Sensitivity} to {Spurious} {Features} in {Prompt} {Design} or},
	url = {http://arxiv.org/abs/2310.11324},
	abstract = {As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FORMATSPREAD, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights1. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.},
	language = {en},
	urldate = {2024-07-26},
	publisher = {arXiv},
	author = {Sclar, Melanie and Choi, Yejin and Tsvetkov, Yulia and Suhr, Alane},
	month = jul,
	year = {2024},
	note = {arXiv:2310.11324 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Sclar et al. - 2024 - Quantifying Language Models' Sensitivity to Spurio.pdf:/home/timo/Zotero/storage/2ZYV98Q9/Sclar et al. - 2024 - Quantifying Language Models' Sensitivity to Spurio.pdf:application/pdf},
}

@misc{cohn_forgotten_nodate,
	title = {The {Forgotten} {Layer} of the {Test} {Automation} {Pyramid}},
	url = {https://www.mountaingoatsoftware.com/blog/the-forgotten-layer-of-the-test-automation-pyramid},
	abstract = {An effective test automation strategy calls for automating tests at three different levels, also known as the test automation pyramid.},
	language = {en},
	urldate = {2024-07-29},
	author = {Cohn, Mike},
	file = {Snapshot:/home/timo/Zotero/storage/82XXXAV9/the-forgotten-layer-of-the-test-automation-pyramid.html:text/html},
}

@inproceedings{gupta_prevalence_2022,
	title = {Prevalence of {GitOps}, {DevOps} in {Fast} {CI}/{CD} {Cycles}},
	volume = {1},
	url = {https://ieeexplore.ieee.org/abstract/document/9850786},
	doi = {10.1109/COM-IT-CON54601.2022.9850786},
	abstract = {Today, when we are surrounded by technology, software and applications are making our lives more efficient and easy because of the operations and processes controlled by them. Since the technology is constantly changing at a very high pace, improving and modifying with each development, there is a constant need of is faster and more frequent delivery of the software and applications. Today, most software and applications are built in such a way that they could run across multiple operating environments. Software development is performed using agile principles and the most critical part of it is Continuous Delivery and Continuous Integration (CI/CD). CI/CD aims at automating the process of testing, building, and deploying the commitments made by the developer to the code repository. The use of Container-based applications solves a number of complex problems that are found on CI/CD such as portability, elasticity, visibility, and version control. This modular approach enables a simpler, faster, more secure, and more efficient way of development by more focused teams responsible for specific containers. In this context, a new point of interest in the development process, GitOps, which is more agile, reliable, fast, and efficient in its approach towards better performance levels with cloud-native. The main objective of this paper is to understand the Kubernetes GitOps process by day 2 operations, to access the benefits of implementing GitOps in the Kubernetes environment, and to implement Kubernetes GitOps on AWS.},
	urldate = {2024-07-29},
	booktitle = {2022 {International} {Conference} on {Machine} {Learning}, {Big} {Data}, {Cloud} and {Parallel} {Computing} ({COM}-{IT}-{CON})},
	author = {Gupta, Saumya and Bhatia, Madhulika and Memoria, Meenakshi and Manani, Preeti},
	month = may,
	year = {2022},
	keywords = {AWS, CI/CD, Codes, Continuous Delivery, Continuous Integration, DevOps, Elasticity, GitOps, Machine learning, Parallel processing, Process control, Productivity, Syntactics},
	pages = {589--596},
	file = {IEEE Xplore Abstract Record:/home/timo/Zotero/storage/3Q65RZ59/9850786.html:text/html;IEEE Xplore Full Text PDF:/home/timo/Zotero/storage/JQRVHXEY/Gupta et al. - 2022 - Prevalence of GitOps, DevOps in Fast CICD Cycles.pdf:application/pdf},
}

@misc{noauthor_llama_nodate,
	title = {Llama 3.1},
	url = {https://llama.meta.com/},
	abstract = {The open source AI model you can fine-tune, distill and deploy anywhere. Our latest models are available in 8B, 70B, and 405B variants.},
	language = {en},
	urldate = {2024-07-30},
	journal = {Meta Llama},
	file = {Snapshot:/home/timo/Zotero/storage/GIKF8DKW/llama.meta.com.html:text/html},
}

@misc{noauthor_gpt-4o_nodate,
	title = {{GPT}-4o contributions},
	url = {https://openai.com/gpt-4o-contributions/},
	abstract = {GPT-4o contributions},
	language = {en-US},
	urldate = {2024-08-01},
	file = {Snapshot:/home/timo/Zotero/storage/P5XF6CY3/gpt-4o-contributions.html:text/html},
}

@misc{colin_zalando_2024,
	title = {Zalando {Engineering} {Blog} - {End}-to-end test probes with {Playwright}},
	url = {https://engineering.zalando.com/posts/2024/07/../../../posts/2024/07/end-to-end-test-probes-with-playwright.html},
	abstract = {Learn how we set up reliable automated end-to-end test probes for our Zalando website using Playwright},
	language = {en},
	urldate = {2024-08-01},
	journal = {Zalando Engineering Blog},
	author = {Colin, Jeremy},
	month = jul,
	year = {2024},
	note = {Section: Zalando},
	file = {Snapshot:/home/timo/Zotero/storage/FTKUYZLW/end-to-end-test-probes-with-playwright.html:text/html},
}
